https://blog.csdn.net/wenqiang1208/article/details/69669084

# 问题1 给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？

问题分析：40亿 ?不重复 ，没有排序。

40亿个unsigned int的整数，放到内存中的话，大约是16G，

(1)最直观的的解决办法，把所有的数据遍历一遍，找出那个数.
注意：这个方法是不可取的，因为把所有数据遍历一遍，要把所有的数据加载到内存中，16G的数据可能内存存储不下。
(2)基于第一种方法，内存加载不了16G的数据，就可以考虑到 外部排序：归并排序的方法，先将一部分数据加载到内存中，然后查找。
(3)可以考虑使用位图bitmap，1个bit存储一个数字，那么40亿数据需要40亿bit 大约就是500M内存。
用一个bit位来表示这个数据是否存在，1表示存在，0表示不存在。
时间复杂度为O(n) ? + 查找时间O(1)。
(4)这个问题在《编程珠玑》里有很好的描述，大家可以参考下面的思路，探讨一下：

又因为2^32为40亿多，所以给定一个数可能在，也可能不在其中；
这里我们把40亿个数中的每一个用32位的二进制来表示
假设这40亿个数开始放在一个文件中。

然后将这40亿个数分成两类:
     
     1.最高位为0
	 2.最高位为1

并将这两类分别写入到两个文件中，其中一个文件中数的个数<=20亿，而另一个>=20亿（这相当于折半了）；

	与要查找的数的最高位比较并接着进入相应的文件再查找

再然后把这个文件为又分成两类:
	
	1.次最高位为0
	2.次最高位为1

并将这两类分别写入到两个文件中，其中一个文件中数的个数<=10亿，而另一个>=10亿（这相当于折半了）；
与要查找的数的次最高位比较并接着进入相应的文件再查找。
	
	以此类推，就可以找到了,而且时间复杂度为O(logn)

	

	
# 问题2  100亿个数，求最大的1万个数，并说出算法的时间复杂度。

用小根堆来实现。注意是小根堆，
读入1万个数，然后做
时间复杂度是O（NlogK）


# 问题三 找出1-10w中没有出现的两个数字。
1） 位图，申请10w个bit的空间，每个bit代表一个数字是否出现过。

开始时将这10w个bit都初始化为0，表示所有数字都没有出现过。然后依次读入已经打乱循序的数字，并将对应的bit设为1。当处理完所有数字后，根据为0的bit得出没有出现的数字。

2） 首先计算1到10w的和，平方和。然后计算给定数字的和，平方和。两次的到的数字相减，可以得到这两个数字的和，平方和。所以我们有x + y = n x^2 + y^2 = m 解方程可以得到x和y的值。


#问题四  有千万个string在内存怎么高速查找，插入和删除？？？
对千万个string做hash，可以实现高速查找，找到了，插入和删除就很方便了。
关键是如何做hash，对string做hash，要减少碰撞频率。


#问题五  一个大的含有50M个URL的记录，一个小的含有500个URL的记录，找出两个记录里相同的URL

	首先使用包含500个url的文件创建一个hash_set。
	然后遍历50M的url记录，如果url在hash_set中，则输出此url并从hash_set中删除这个url。
	所有输出的url就是两个记录里相同的url。


#问题 6 一个网站有 海量日志数据，提取出某日访问该网站次数最多的那个IP
2、上千万条记录，统计出重复记录最多的前N条。

首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。

	注意到IP是32位的，最多有个2^32个IP。

同样可以采用映射的方法，比如模1000，把整个大文件映射为1000个小文件，

再找出每个小文中出现频率最大的IP（可以采用hash_map进行频率统计，然后再找出频率最大的几个）及相应的频率。
然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。
或者如下阐述（雪域之鹰）：

算法思想：分而治之+Hash：

	1、IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中处理；
	2、可以考虑采用分而治之的思想，按照IP地址的Hash(IP) % 1024值，把海量IP日志分别存储到1024个小文件中，这样，每个小文件最多包含4MB个IP地址；
	        这里解释一下为什么用Hash(IP) % 1024值，如果不用，而直接分类的话，可能会出现这样一种情况，就是有个IP在每个小文件中都存在，而且这个IP并不一定在那个小文件中是数量最多的，那么最终可能选择的结果会有问题，所以这里用了Hash(IP)%1024值，这样的话，通过计算IP的Hash值，相同IP肯定会放到一个文件中，当然了不同的IP的Hash值也可能相同，就存在一个小文件中。
	3、对于每一个小文件，可以构建一个IP为key，出现的次数为value的Hash Map，同时记录当前出现次数最多的那个IP地址；
	4、可以得到1024个小文件中的出现次数最多的那个IP，再依据常规的排序算法得出总体上出现次数最多的IP。



#问题七 从300万字符串中找到最热门的10条
搜索的输入信息是一个字符串，统计300万输入信息中的最热门的前10条，我们每次输入的一个字符串为不超过255byte，内存使用只有1G。请描述思想，写出算法（c语言），空间和时间复杂度。

答案： 

此题是可以全部存放入内存中的情况。
	
	256B=0.25KB=1KB/4；100万=1M，10亿=1G。
	
300万个字符串最多（假设没有重复，都是最大长度）占用内存3M*1K/4=0.75G。所以可以将所有字符串都存放在内存中进行处理。 

  
	  1  可以使用key为字符串（事实上是字符串的hash值），值为字符串出现次数的hash来统计每个每个字符串出现的次数。	
	  2 用一个长度为10的数组/链表来存储目前出现次数最多的10个字符串。 

这样空间和时间的复杂度都是O(n)。


#问题八  有两个字符串数组： string src[]  和 string des[]，每个字符串数组的长度都是10W跳左右，每个字符的 size<1KB ，设计一个算法 查找 两个字符串数组中想交的字符串。

解析方法：

分析 10W = 2^20  1KB*10W*2 = 2GB ，当今的内存中正好可以容下这么多数据，算法设计

（1）遍历字符串数组src，构造一个 tire tree（字典数），然后遍历字符串数组des遇到已经存储过的相同的结构则输出。

（2）设计一个hash，关键是哈希算法的设计，因为这是一个字符串数组，每个字符都是有范围的(0~25)，我们可以字符串数组中的每个字符串看成一个26进制的数，将其转化为10进制，这样就可以得到一个唯一的key值，对于字符串太长的情况下，我们可以将这个字符串对10万取模，对10万取模后，我们并不能保证这个key唯一，这样我们就需要key值冲突处理，参考以下四种处理方式：http://blog.csdn.net/leo115/article/details/8052353

说明：同样可以直接使用string类型的字符串作为 hash key，每个string的ASCII码是不同的，所以具有唯一性，故可以直接作为 hash key。
